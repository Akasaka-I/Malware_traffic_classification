import os
import numpy as np
from PIL import Image
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
import pandas as pd
import seaborn as sns
from tqdm import tqdm

# Define dataset class
class CustomDataset(Dataset):
    def __init__(self, images, labels):
        self.images = images
        self.labels = labels
        self.classes = list(set(labels))
        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}
        self.idx_to_class = {idx: cls for cls, idx in self.class_to_idx.items()}
        
        self.labels = [self.class_to_idx[label] for label in labels]

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        image = self.images[idx].astype(np.float32) / 255.0
        image = torch.tensor(image).permute(2, 0, 1)  # Convert to (C, H, W)
        label = self.labels[idx]
        return image, label

# Read data function
def readData(readDataPath):
    img = []
    label = []

    # get all folder name
    imagePathList = []
    for folderName in os.listdir(readDataPath):
        imagePathList.append(readDataPath + '/' + folderName)

    # read all image
    for folder in tqdm(imagePathList):
        labelName = folder.split('/')[-1]
        for imageFile in tqdm(os.listdir(folder), leave=False):
            imageArray = np.array(Image.open(folder + '/' + imageFile).convert('L'))  # Convert image to grayscale

            imageArray = imageArray[:, :, np.newaxis]  # Add channel dimension

            img.append(imageArray)
            label.append(labelName)

    img = np.stack(img, axis=0)
    return img, label, len(imagePathList)

# Define CNN model
class CNNModel(nn.Module):
    def __init__(self, num_classes):
        super(CNNModel, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)
        self.fc1 = nn.Linear(64 * 7 * 7, 128)  # Adjust the input size based on the output of conv2 and pool layers
        self.fc2 = nn.Linear(128, num_classes)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.pool(self.relu(self.conv1(x)))
        x = self.pool(self.relu(self.conv2(x)))
        x = x.view(-1, 64 * 7 * 7)  # Adjust the input size based on the output of conv2 and pool layers
        x = self.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# Main function
def main(readDataPath, batch_size=32, epochs=10, learning_rate=0.001):
    # Read data
    images, labels, num_classes = readData(readDataPath)
    
    # Encode labels
    labelEncoder = LabelEncoder()
    labels = labelEncoder.fit_transform(labels)
    # Split data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)
    
    train_dataset = CustomDataset(X_train, y_train)
    test_dataset = CustomDataset(X_test, y_test)
    
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)
    
    # Check if GPU is available
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # Initialize model, loss function and optimizer
    model = CNNModel(num_classes).to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)
    
    # Initialize lists to store loss and accuracy for each epoch
    epoch_losses = []
    epoch_accuracies = []

    # Training loop
    for epoch in range(epochs):
        model.train()
        running_loss = 0.0
        y_true = []
        y_pred = []
        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)  # Move data to the device
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)  # Remove l2_loss as it is not defined
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            y_true.extend(labels.cpu().numpy())
            y_pred.extend(predicted.cpu().numpy())

        avg_loss = running_loss / len(train_loader)
        accuracy = accuracy_score(y_true, y_pred)
        precision = precision_score(y_true, y_pred, average='macro', zero_division=0)
        recall = recall_score(y_true, y_pred, average='macro', zero_division=0)
        f1 = f1_score(y_true, y_pred, average='macro')
        epoch_losses.append(avg_loss)
        epoch_accuracies.append(accuracy)

        print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')

        # Step the scheduler
        scheduler.step()
    # Plot training loss and accuracy
    plt.figure(figsize=(12, 6))

    plt.subplot(1, 2, 1)
    plt.plot(range(1, epochs+1), epoch_losses, marker='o', color='blue')
    plt.title('Epoch vs Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')

    plt.subplot(1, 2, 2)
    plt.plot(range(1, epochs+1), epoch_accuracies, marker='o', color='red')
    plt.title('Epoch vs Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')

    plt.tight_layout()
    plt.savefig('training_performance.png')
    plt.show()

    # Testing loop
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for data in test_loader:
            inputs, labels = data
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    
    print(f'Accuracy on test set: {100 * correct / total:.2f}%')
    with torch.no_grad():
        y_true = []
        y_pred = []
        for inputs, labels in test_loader:
            inputs, labels = inputs.to(device), labels.to(device)  # Move data to the device
            outputs = model(inputs)
            _, predicted = torch.max(outputs.data, 1)
            y_true.extend(labels.cpu().numpy())
            y_pred.extend(predicted.cpu().numpy())

        accuracy = accuracy_score(y_true, y_pred)
        precision = precision_score(y_true, y_pred, average='macro', zero_division=0)
        recall = recall_score(y_true, y_pred, average='macro', zero_division=0)
        f1 = f1_score(y_true, y_pred, average='macro')

        print(f'Test Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')

        # Confusion matrix
        cm = confusion_matrix(y_true, y_pred)
        labels = labelEncoder.inverse_transform(range(num_classes))
        df_cm = pd.DataFrame(cm, index=labels, columns=labels)
        plt.figure(figsize=(15, 8))
        sns.heatmap(df_cm, annot=True, fmt='d', cmap='Blues', yticklabels=True)
        plt.xlabel('Predicted')
        plt.ylabel('Actual', rotation=0)
        plt.xticks(rotation=0)  
        plt.yticks(rotation=0)  
        plt.title('Confusion Matrix')
        plt.savefig('confusion_matrix.png')
        plt.show()
# Usage
# Replace 'your_data_path' with the actual path to your data
main('virusPcapImage')
